{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ccf1c78a",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/mohsennasab/python-fundamentals-hh/blob/main/notebooks/02_timeseries/02_01_TimeSeries_Basics.ipynb\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Module 2, Lesson 1: Time Series Analysis for H&H with Python\n",
        "\n",
        "## Working with USGS daily discharge data (Mississippi River at St. Paul, MN)\n",
        "\n",
        "---\n",
        "\n",
        "### Welcome!\n",
        "\n",
        "In this lesson, you'll learn the time series skills you'll use constantly in hydrology and hydraulics: reading data, parsing dates, resampling, unit conversions, plotting hydrographs, and calculating common summary statistics.\n",
        "\n",
        "We'll use a real dataset: **USGS daily discharge (cfs)** for **USGS 05331000** (Mississippi River at St. Paul, Minnesota).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ¤– About AI Assistance in This Course\n",
        "\n",
        "Throughout this lesson, you'll see **\"ðŸ¤– AI Assistant Prompt\"** boxes. These are ready-to-use prompts you can copy and paste into your favorite AI assistant (ChatGPT, Claude, Gemini, Copilot, etc.) to:\n",
        "\n",
        "- Get explanations of code you don't understand\n",
        "- Debug errors you encounter\n",
        "- Modify code for your own projects\n",
        "- Learn the \"why\" behind each step\n",
        "\n",
        "**Using AI is not cheatingâ€”it's a professional skill.** Engineers use AI assistants daily. The goal is to understand what the code does, not memorize every syntax detail."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "note",
      "metadata": {
        "id": "note"
      },
      "source": [
        "> **Note:** In this module we use **streamflow (discharge)** as our example time series. The same workflows apply to most water-resources time series: **precipitation**, **snow water equivalent**, **water level/stage**, **groundwater levels**, **water temperature**, **turbidity**, and **water quality** measurements. Once you learn these skills, you can reuse them across datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "objectives",
      "metadata": {
        "id": "objectives"
      },
      "source": [
        "### What you'll be able to do by the end\n",
        "\n",
        "After completing this lesson, you will be able to:\n",
        "\n",
        "1. **Read a CSV time series** and parse datetime correctly\n",
        "2. **Set a datetime index** and do time-based slicing (e.g., \"give me just 2020 data\")\n",
        "3. **Handle missing values** and common data issues\n",
        "4. **Convert units** (cfs â†” cms) and aggregate to different time steps (daily â†’ monthly)\n",
        "5. **Make common plots** for time series: Hydrograph, Flow Duration Curve, Box Plots\n",
        "6. **Compute basic statistics** (min/mean/max, percentiles, annual metrics)\n",
        "7. **Use AI as a pair programmer** to explain, write, debug, and improve your code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ai_howto",
      "metadata": {
        "id": "ai_howto"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ¤– How to Use AI Assistants Effectively\n",
        "\n",
        "### The Three Types of AI Prompts You'll Use\n",
        "\n",
        "| Type | When to Use | Example |\n",
        "|------|-------------|--------|\n",
        "| **Explain** | You see code and want to understand it | \"Explain this code line by line...\" |\n",
        "| **Debug** | Something isn't working | \"I got this error... what's wrong?\" |\n",
        "| **Modify** | You want to adapt code for your needs | \"How do I change this to use my data?\" |\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "1. **Always include the code** when asking questions\n",
        "2. **Include the full error message** when debugging\n",
        "3. **Describe your goal**, not just what you tried\n",
        "4. **Ask follow-up questions** if the explanation isn't clear\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ai_prompts_module",
      "metadata": {
        "id": "ai_prompts_module"
      },
      "source": [
        "### ðŸ¤– AI Assistant Prompts for This Module\n",
        "\n",
        "**For understanding code:**\n",
        "```\n",
        "I'm learning Python for hydrology. Explain what this code is doing line by line,\n",
        "and point out any assumptions. Use simple language:\n",
        "\n",
        "[paste code here]\n",
        "```\n",
        "\n",
        "**For debugging:**\n",
        "```\n",
        "I'm working in Google Colab on a hydrology project. I got this error:\n",
        "\n",
        "[paste error message]\n",
        "\n",
        "Here's my code:\n",
        "\n",
        "[paste code]\n",
        "\n",
        "What does this error mean and how do I fix it?\n",
        "```\n",
        "\n",
        "**For modifying code:**\n",
        "```\n",
        "I have this Python code that works with discharge data:\n",
        "\n",
        "[paste code]\n",
        "\n",
        "How would I modify it to [describe your goal]?\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structure",
      "metadata": {
        "id": "structure"
      },
      "source": [
        "### Lesson Structure\n",
        "\n",
        "1. **Mental models** for time series (connecting to concepts you already know)\n",
        "2. **Load and clean** USGS discharge data\n",
        "3. **Datetimes**: parsing, time zones, indexing, slicing\n",
        "4. **Resampling and aggregation** (daily â†’ weekly/monthly)\n",
        "5. **Visualization patterns** you'll reuse in reports\n",
        "6. **Practical statistics** for H&H\n",
        "7. **Mini-project**: a clean \"hydrograph summary\" workflow\n",
        "8. **Practice exercises** (with AI prompts for help)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mental_models",
      "metadata": {
        "id": "mental_models"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 1: Mental Models for Time Series\n",
        "\n",
        "### What is a Time Series? (The Excel Analogy)\n",
        "\n",
        "If you've worked with Excel, you already understand time series data. It's simply a table where:\n",
        "- **One column contains dates/times** (when the measurement was taken)\n",
        "- **Another column contains values** (what was measured)\n",
        "\n",
        "Think of it like a gage record from USGS:\n",
        "\n",
        "| Date | Discharge (cfs) |\n",
        "|------|----------------|\n",
        "| 2024-01-01 | 5,000 |\n",
        "| 2024-01-02 | 5,200 |\n",
        "| 2024-01-03 | 4,800 |\n",
        "\n",
        "### Why Time Series Needs Special Handling\n",
        "\n",
        "In hydrology, almost everything is \"value vs time\":\n",
        "- **Rainfall hyetographs** (precipitation rate over time)\n",
        "- **Streamflow hydrographs** (discharge over time)\n",
        "- **Stage records** (water level over time)\n",
        "- **Snow water equivalent (SWE)** over a season\n",
        "\n",
        "In Python (using pandas), your job is to:\n",
        "\n",
        "1. **Make sure time is truly a datetime type** (not just text)\n",
        "2. **Make time the index** (so slicing and resampling work cleanly)\n",
        "3. **Keep units and time step clear** (daily vs hourly vs 15-min)\n",
        "\n",
        "### âš ï¸ A Helpful Rule\n",
        "\n",
        "> If your time column is still \"object\" or \"string\" type, treat it as **not ready** for analysis!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ai_timeseries",
      "metadata": {
        "id": "ai_timeseries"
      },
      "source": [
        "---\n",
        "\n",
        "### ðŸ¤– AI Assistant Prompt: Understanding Time Series\n",
        "\n",
        "```\n",
        "I'm a water resources engineer learning Python. Explain what a \"datetime index\" is\n",
        "in pandas and why it's useful for hydrologic time series data.\n",
        "Compare it to how I might work with dates in Excel.\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup_section",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## Part 2: Setup (Run Once at the Start)\n",
        "\n",
        "### What are \"Imports\"?\n",
        "\n",
        "Think of imports like loading toolboxes in a workshop. Before you can use a power drill, you need to get it out of storage.\n",
        "\n",
        "We'll use three main libraries:\n",
        "\n",
        "| Library | What It Does | Analogy |\n",
        "|---------|--------------|--------|\n",
        "| `pandas` | Data manipulation (tables, filtering, aggregating) | Excel on steroids |\n",
        "| `matplotlib` | Creating plots and charts | Like Excel charts, but more flexible |\n",
        "| `numpy` | Numerical calculations | A powerful calculator |\n",
        "\n",
        "> **If you see an import error:** Copy the error message and ask your AI assistant: \"What do I need to install in Colab to fix this?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# IMPORTS - Run this cell first!\n",
        "# =============================================================================\n",
        "# These are the \"toolboxes\" we'll use throughout this lesson.\n",
        "\n",
        "import pandas as pd      # pd is a nickname (alias) so we type less\n",
        "import numpy as np       # np is the standard nickname for numpy\n",
        "import matplotlib.pyplot as plt  # plt is standard for plotting\n",
        "\n",
        "# These settings make tables display nicely in Colab\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "pd.set_option(\"display.width\", 120)\n",
        "\n",
        "print(\"âœ“ All libraries loaded successfully!\")\n",
        "print(f\"  - pandas version: {pd.__version__}\")\n",
        "print(f\"  - numpy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_imports",
      "metadata": {
        "id": "explain_imports"
      },
      "source": [
        "### ðŸ” Understanding the Code Above\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "```\n",
        "\n",
        "This line:\n",
        "1. **`import pandas`** - Loads the pandas library\n",
        "2. **`as pd`** - Creates a shorter nickname\n",
        "\n",
        "Instead of typing `pandas.read_csv()`, we can now type `pd.read_csv()`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ai_imports",
      "metadata": {
        "id": "ai_imports"
      },
      "source": [
        "---\n",
        "\n",
        "### ðŸ¤– AI Assistant Prompt: Understanding Imports\n",
        "\n",
        "```\n",
        "I'm new to Python. Explain what these import statements do and why we use\n",
        "nicknames like 'pd' and 'np':\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load_data",
      "metadata": {
        "id": "load_data"
      },
      "source": [
        "## Part 3: Loading the USGS Dataset ðŸ“¥\n",
        "\n",
        "### About the Data\n",
        "\n",
        "We're using real USGS daily discharge data for the Mississippi River at St. Paul, MN (Station 05331000).\n",
        "\n",
        "**What's in the file:**\n",
        "- ~25 years of daily discharge measurements\n",
        "- Values in cubic feet per second (cfs)\n",
        "- Quality flags and metadata\n",
        "\n",
        "### Getting Data into Colab\n",
        "\n",
        "We'll show you **two beginner-friendly methods** to load a CSV:\n",
        "\n",
        "1. **Upload from your computer** (easiest for beginners)\n",
        "2. **Load from Google Drive** (better for repeated use)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "upload_method",
      "metadata": {
        "id": "upload_method"
      },
      "source": [
        "### Method 1: Upload from Your Computer\n",
        "\n",
        "Run the cell below. A \"Choose Files\" button will appear. Click it and select your CSV file.\n",
        "\n",
        "> **First time?** Download the file from the course GitHub repository first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "upload_cell",
      "metadata": {
        "id": "upload_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# METHOD 1: Upload a file from your computer\n",
        "# =============================================================================\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Click 'Choose Files' below and select your CSV file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename of what was uploaded\n",
        "uploaded_filename = next(iter(uploaded))\n",
        "data_path = uploaded_filename\n",
        "\n",
        "print(f\"\\nâœ“ File uploaded successfully!\")\n",
        "print(f\"  Filename: {data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_upload",
      "metadata": {
        "id": "explain_upload"
      },
      "source": [
        "### ðŸ” What Just Happened?\n",
        "\n",
        "1. **`from google.colab import files`** - Loads Colab's file upload tool\n",
        "2. **`files.upload()`** - Opens a file picker in your browser\n",
        "3. **`uploaded`** - A dictionary containing your file(s)\n",
        "4. **`next(iter(uploaded))`** - Gets the name of the first uploaded file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ai_upload",
      "metadata": {
        "id": "ai_upload"
      },
      "source": [
        "---\n",
        "\n",
        "### ðŸ¤– AI Assistant Prompt: File Upload Issues\n",
        "\n",
        "```\n",
        "I'm using Google Colab and trying to upload a CSV file. The files.upload()\n",
        "function ran but I got this error:\n",
        "\n",
        "[paste your error here]\n",
        "\n",
        "What's wrong and how do I fix it?\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "read_section",
      "metadata": {
        "id": "read_section"
      },
      "source": [
        "### Reading the CSV File\n",
        "\n",
        "Now let's load the data into a pandas **DataFrame**. A DataFrame is pandas' version of a spreadsheetâ€”a table with rows and columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "read_csv",
      "metadata": {
        "id": "read_csv"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# READ THE CSV FILE\n",
        "# =============================================================================\n",
        "# pd.read_csv() is the main function for loading CSV files.\n",
        "\n",
        "raw = pd.read_csv(data_path)\n",
        "\n",
        "# Let's see what we got:\n",
        "print(f\"Dataset shape: {raw.shape[0]} rows Ã— {raw.shape[1]} columns\")\n",
        "print(f\"\\nColumn names:\")\n",
        "for col in raw.columns:\n",
        "    print(f\"  - {col}\")\n",
        "\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_read",
      "metadata": {
        "id": "explain_read"
      },
      "source": [
        "### ðŸ” Understanding `pd.read_csv()`\n",
        "\n",
        "```python\n",
        "raw = pd.read_csv(data_path)\n",
        "```\n",
        "\n",
        "- **`pd.read_csv()`** - Reads a CSV file and creates a DataFrame\n",
        "- **`data_path`** - The filename (or full path) to your CSV\n",
        "- **`raw`** - We store the result in a variable called `raw` (for \"raw data\")\n",
        "\n",
        "The **`.shape`** attribute tells you dimensions: `(rows, columns)`\n",
        "\n",
        "The **`.head()`** method shows the first 5 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "audit_section",
      "metadata": {
        "id": "audit_section"
      },
      "source": [
        "### Quick Data Audit\n",
        "\n",
        "Before doing any analysis, always check:\n",
        "- What columns exist?\n",
        "- What **type** is each column? (especially: is the date a proper datetime?)\n",
        "- Are there missing values?\n",
        "\n",
        "The **`.info()`** method gives us all of this at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "info_cell",
      "metadata": {
        "id": "info_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DATA AUDIT: Check column types and missing values\n",
        "# =============================================================================\n",
        "# .info() is your best friend for understanding a new dataset!\n",
        "\n",
        "raw.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_info",
      "metadata": {
        "id": "explain_info"
      },
      "source": [
        "### ðŸ” Reading the `.info()` Output\n",
        "\n",
        "Look at the `Dtype` column:\n",
        "\n",
        "| Dtype | What It Means | Example |\n",
        "|-------|---------------|--------|\n",
        "| `int64` | Integer numbers | 5000, -10, 0 |\n",
        "| `float64` | Decimal numbers | 3.14, -2.5 |\n",
        "| `object` | Text (strings) | \"2024-01-01\", \"Approved\" |\n",
        "| `datetime64` | Proper dates | (what we want for time!) |\n",
        "\n",
        "**Notice:** The `time` column is probably showing as `object`, not `datetime64`. This means Python sees it as text, not as a real date. We'll fix this soon!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ai_info",
      "metadata": {
        "id": "ai_info"
      },
      "source": [
        "---\n",
        "\n",
        "### ðŸ¤– AI Assistant Prompt: Understanding Data Types\n",
        "\n",
        "```\n",
        "I ran .info() on my pandas DataFrame and got this output:\n",
        "\n",
        "[paste your info output here]\n",
        "\n",
        "Explain what each Dtype means and whether any columns need to be converted\n",
        "to different types for time series analysis.\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clean_section",
      "metadata": {
        "id": "clean_section"
      },
      "source": [
        "### Creating a Clean Working Table\n",
        "\n",
        "USGS data files often contain many columns we don't need. Let's:\n",
        "\n",
        "1. Keep only the columns we need\n",
        "2. Rename them to something friendlier\n",
        "\n",
        "**Columns we'll keep:**\n",
        "- `time` â†’ rename to `date`\n",
        "- `value` â†’ rename to `Q_cfs` (Q is the standard symbol for discharge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "clean_cell",
      "metadata": {
        "id": "clean_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CREATE A CLEAN WORKING TABLE\n",
        "# =============================================================================\n",
        "\n",
        "# Step 1: Make a copy so we don't modify the original\n",
        "df = raw.copy()\n",
        "\n",
        "# Step 2: Rename columns to be more intuitive\n",
        "df = df.rename(columns={\n",
        "    \"time\": \"date\",\n",
        "    \"value\": \"Q_cfs\"\n",
        "})\n",
        "\n",
        "# Step 3: Keep only the columns we need\n",
        "keep_cols = [\"date\", \"Q_cfs\", \"unit_of_measure\", \"approval_status\"]\n",
        "df = df[[c for c in keep_cols if c in df.columns]]\n",
        "\n",
        "print(f\"Clean dataset: {df.shape[0]} rows Ã— {df.shape[1]} columns\\n\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_clean",
      "metadata": {
        "id": "explain_clean"
      },
      "source": [
        "### ðŸ” Understanding the Cleaning Code\n",
        "\n",
        "```python\n",
        "df = raw.copy()\n",
        "```\n",
        "Creates a copy of `raw`. If we mess up, the original data is still safe.\n",
        "\n",
        "```python\n",
        "df = df.rename(columns={\"time\": \"date\", \"value\": \"Q_cfs\"})\n",
        "```\n",
        "The `rename()` function uses a **dictionary** `{}` to map old names to new names.\n",
        "\n",
        "```python\n",
        "df = df[[\"date\", \"Q_cfs\", ...]]\n",
        "```\n",
        "This **selects specific columns** using double brackets `[[]]`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "datetime_section",
      "metadata": {
        "id": "datetime_section"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Datetime Parsing and Indexing\n",
        "\n",
        "This is the **most important step** for time series analysis.\n",
        "\n",
        "### Why Datetimes Matter\n",
        "\n",
        "Right now, our `date` column is just text (type \"object\"). Python doesn't know that \"2024-01-01\" is a date.\n",
        "\n",
        "We need to **convert** it to a proper datetime so we can:\n",
        "- Sort by date\n",
        "- Filter by year, month, or date range\n",
        "- Calculate time differences\n",
        "- Resample to different time periods\n",
        "\n",
        "### Step 1: Convert to Datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "datetime_cell",
      "metadata": {
        "id": "datetime_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONVERT DATE COLUMN TO DATETIME\n",
        "# =============================================================================\n",
        "\n",
        "# BEFORE: Check the type\n",
        "print(f\"BEFORE conversion:\")\n",
        "print(f\"  date column type: {df['date'].dtype}\")\n",
        "print(f\"  Example value: {df['date'].iloc[0]} (just text!)\\n\")\n",
        "\n",
        "# CONVERT: Use pd.to_datetime()\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# AFTER: Check the type\n",
        "print(f\"AFTER conversion:\")\n",
        "print(f\"  date column type: {df['date'].dtype}\")\n",
        "print(f\"  Example value: {df['date'].iloc[0]} (now a real datetime!)\\n\")\n",
        "\n",
        "# Check for any failed conversions\n",
        "missing_dates = df['date'].isna().sum()\n",
        "print(f\"  Missing/invalid dates: {missing_dates}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_datetime",
      "metadata": {
        "id": "explain_datetime"
      },
      "source": [
        "### ðŸ” Understanding `pd.to_datetime()`\n",
        "\n",
        "```python\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "```\n",
        "\n",
        "This line:\n",
        "1. **`df['date']`** - Selects the 'date' column\n",
        "2. **`pd.to_datetime()`** - Converts text to datetime\n",
        "3. **`df['date'] = ...`** - Saves the result back\n",
        "\n",
        "Pandas recognizes common date formats automatically!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ai_datetime",
      "metadata": {
        "id": "ai_datetime"
      },
      "source": [
        "---\n",
        "\n",
        "### ðŸ¤– AI Assistant Prompt: Date Format Issues\n",
        "\n",
        "```\n",
        "I'm trying to convert a date column to datetime in pandas. My dates look like this:\n",
        "\n",
        "[paste a few example dates]\n",
        "\n",
        "But pd.to_datetime() is giving me errors. What format string do I need to use?\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "index_section",
      "metadata": {
        "id": "index_section"
      },
      "source": [
        "### Step 2: Set Date as the Index\n",
        "\n",
        "The **index** is like the row labels. For time series, we want the date to be the index because:\n",
        "\n",
        "1. It makes **time-based slicing** easy: `df['2020']` gets all 2020 data\n",
        "2. It enables **resampling**: converting daily to monthly data\n",
        "3. Plots automatically use dates on the x-axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "index_cell",
      "metadata": {
        "id": "index_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SET DATE AS INDEX AND SORT\n",
        "# =============================================================================\n",
        "\n",
        "df = df.sort_values('date')  # Sort chronologically\n",
        "df = df.set_index('date')    # Make date the index\n",
        "\n",
        "print(f\"Index type: {type(df.index).__name__}\")\n",
        "print(f\"Date range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
        "print(f\"\\nFirst 5 rows (notice date is now the index, not a column):\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quality_section",
      "metadata": {
        "id": "quality_section"
      },
      "source": [
        "### Step 3: Basic Quality Checks\n",
        "\n",
        "Before analysis, always verify:\n",
        "- Is the index unique? (no duplicate dates)\n",
        "- Is the time step consistent?\n",
        "- Are there gaps in the record?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "quality_cell",
      "metadata": {
        "id": "quality_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# QUALITY CHECKS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=== Data Quality Checks ===\")\n",
        "print(f\"\\n1. Index unique?: {df.index.is_unique}\")\n",
        "print(f\"\\n2. Date range: {df.index.min()} to {df.index.max()}\")\n",
        "\n",
        "# Check time step\n",
        "time_deltas = df.index.to_series().diff().dropna()\n",
        "print(f\"\\n3. Most common time step (days):\")\n",
        "print(time_deltas.dt.days.value_counts().head(3))\n",
        "\n",
        "print(f\"\\n4. Missing discharge values: {df['Q_cfs'].isna().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "slicing_section",
      "metadata": {
        "id": "slicing_section"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 5: Time-Based Slicing (Filtering by Date)\n",
        "\n",
        "One of the biggest benefits of a datetime index is easy **slicing**â€”selecting data for specific time periods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "slicing_cell",
      "metadata": {
        "id": "slicing_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TIME-BASED SLICING EXAMPLES\n",
        "# =============================================================================\n",
        "\n",
        "# Get all data for a specific year\n",
        "print(\"=== All 2020 data (first 5 rows) ===\")\n",
        "print(df.loc['2020'].head())\n",
        "\n",
        "# Get data for a specific month\n",
        "print(\"\\n=== June 2020 data (first 5 rows) ===\")\n",
        "print(df.loc['2020-06'].head())\n",
        "\n",
        "# Get data for a date range\n",
        "print(\"\\n=== May 1-15, 2020 ===\")\n",
        "print(df.loc['2020-05-01':'2020-05-15'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_slicing",
      "metadata": {
        "id": "explain_slicing"
      },
      "source": [
        "### ðŸ” Understanding Time-Based Slicing\n",
        "\n",
        "| Code | Result |\n",
        "|------|--------|\n",
        "| `df.loc['2020']` | All rows from year 2020 |\n",
        "| `df.loc['2020-06']` | All rows from June 2020 |\n",
        "| `df.loc['2020-06-15']` | Just June 15, 2020 |\n",
        "| `df.loc['2020':'2022']` | All data from 2020 through 2022 |\n",
        "\n",
        "This only works **because we set the date as the index**!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unit_section",
      "metadata": {
        "id": "unit_section"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Unit Conversion (cfs â†” cms)\n",
        "\n",
        "**Conversion factor:** 1 cfs = 0.028317 cms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unit_cell",
      "metadata": {
        "id": "unit_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# UNIT CONVERSION: cfs to cms\n",
        "# =============================================================================\n",
        "\n",
        "CFS_TO_CMS = 0.028317\n",
        "\n",
        "# Create a new column with converted values\n",
        "df['Q_cms'] = df['Q_cfs'] * CFS_TO_CMS\n",
        "\n",
        "print(\"Discharge in both units (first 5 rows):\")\n",
        "print(df[['Q_cfs', 'Q_cms']].head())\n",
        "\n",
        "print(f\"\\nMean discharge: {df['Q_cfs'].mean():,.0f} cfs = {df['Q_cms'].mean():,.1f} cms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "resample_section",
      "metadata": {
        "id": "resample_section"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 7: Resampling (Changing Time Steps)\n",
        "\n",
        "Often you need to **aggregate** data to different time periods:\n",
        "\n",
        "| Code | Meaning |\n",
        "|------|--------|\n",
        "| `'D'` | Daily |\n",
        "| `'W'` | Weekly |\n",
        "| `'MS'` | Month Start |\n",
        "| `'YS'` | Year Start |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "resample_cell",
      "metadata": {
        "id": "resample_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# RESAMPLE TO MONTHLY DATA\n",
        "# =============================================================================\n",
        "\n",
        "monthly_mean = df['Q_cfs'].resample('MS').mean()\n",
        "\n",
        "print(\"Monthly Mean Discharge (first 12 months):\")\n",
        "print(monthly_mean.head(12))\n",
        "\n",
        "print(f\"\\nOriginal: {len(df)} daily values\")\n",
        "print(f\"After resampling: {len(monthly_mean)} monthly values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_resample",
      "metadata": {
        "id": "explain_resample"
      },
      "source": [
        "### ðŸ” Understanding `.resample()`\n",
        "\n",
        "```python\n",
        "monthly_mean = df['Q_cfs'].resample('MS').mean()\n",
        "```\n",
        "\n",
        "Think of it as a two-step process:\n",
        "1. **`resample('MS')`** - Groups data by month\n",
        "2. **`.mean()`** - Calculates the average for each group\n",
        "\n",
        "You can replace `.mean()` with `.max()`, `.min()`, `.sum()`, `.median()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rolling_cell",
      "metadata": {
        "id": "rolling_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ROLLING AVERAGES\n",
        "# =============================================================================\n",
        "\n",
        "# Calculate 7-day and 30-day rolling means\n",
        "df['Q_7day'] = df['Q_cfs'].rolling(window=7).mean()\n",
        "df['Q_30day'] = df['Q_cfs'].rolling(window=30).mean()\n",
        "\n",
        "print(\"Daily vs Rolling Averages (sample period):\")\n",
        "print(df.loc['2020-05-01':'2020-05-15', ['Q_cfs', 'Q_7day', 'Q_30day']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "plot_section",
      "metadata": {
        "id": "plot_section"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 8: Visualization Patterns for H&H\n",
        "\n",
        "### Plot 1: Basic Hydrograph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot1_cell",
      "metadata": {
        "id": "plot1_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PLOT 1: BASIC HYDROGRAPH\n",
        "# =============================================================================\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "\n",
        "ax.plot(df.index, df['Q_cfs'], linewidth=0.5, color='steelblue')\n",
        "\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Discharge (cfs)')\n",
        "ax.set_title('Mississippi River at St. Paul, MN - Daily Discharge')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_plot",
      "metadata": {
        "id": "explain_plot"
      },
      "source": [
        "### ðŸ” Understanding Matplotlib Plotting\n",
        "\n",
        "```python\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "```\n",
        "- **`fig`** = the overall figure (like a canvas)\n",
        "- **`ax`** = the axes where we draw\n",
        "- **`figsize=(12, 5)`** = width and height in inches\n",
        "\n",
        "```python\n",
        "ax.plot(df.index, df['Q_cfs'], linewidth=0.5, color='steelblue')\n",
        "```\n",
        "- First argument = x-values (dates)\n",
        "- Second argument = y-values (discharge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ai_plot",
      "metadata": {
        "id": "ai_plot"
      },
      "source": [
        "---\n",
        "\n",
        "### ðŸ¤– AI Assistant Prompt: Customizing Plots\n",
        "\n",
        "```\n",
        "I made this matplotlib plot:\n",
        "\n",
        "[paste your plotting code]\n",
        "\n",
        "I want to modify it to [describe changes, e.g., \"add a horizontal line at 10,000 cfs\",\n",
        "\"change the x-axis to only show 2020-2022\"].\n",
        "\n",
        "Show me how.\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "plot2_section",
      "metadata": {
        "id": "plot2_section"
      },
      "source": [
        "### Plot 2: Monthly Box Plot (Seasonal Patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot2_cell",
      "metadata": {
        "id": "plot2_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PLOT 2: MONTHLY BOX PLOT\n",
        "# =============================================================================\n",
        "\n",
        "df['month'] = df.index.month\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "df.boxplot(column='Q_cfs', by='month', ax=ax)\n",
        "\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Discharge (cfs)')\n",
        "ax.set_title('Seasonal Distribution of Discharge')\n",
        "fig.suptitle('')\n",
        "\n",
        "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "ax.set_xticklabels(month_names)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc_section",
      "metadata": {
        "id": "fdc_section"
      },
      "source": [
        "### Plot 3: Flow Duration Curve (FDC)\n",
        "\n",
        "The **Flow Duration Curve** shows what discharge is exceeded X% of the time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc_cell",
      "metadata": {
        "id": "fdc_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PLOT 3: FLOW DURATION CURVE\n",
        "# =============================================================================\n",
        "\n",
        "q = df['Q_cfs'].dropna().values\n",
        "q_sorted = np.sort(q)[::-1]\n",
        "n = len(q_sorted)\n",
        "exceedance = np.arange(1, n+1) / (n+1) * 100\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "ax.plot(exceedance, q_sorted, color='steelblue', linewidth=1)\n",
        "\n",
        "ax.set_xlabel('Exceedance Probability (%)')\n",
        "ax.set_ylabel('Discharge (cfs)')\n",
        "ax.set_title('Flow Duration Curve')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explain_fdc",
      "metadata": {
        "id": "explain_fdc"
      },
      "source": [
        "### ðŸ” Understanding the Flow Duration Curve\n",
        "\n",
        "**How to read it:**\n",
        "- **X-axis** = Exceedance probability (% of time flow is exceeded)\n",
        "- **Y-axis** = Discharge\n",
        "- **Q10** = Flow exceeded 10% of time (high flow)\n",
        "- **Q50** = Flow exceeded 50% of time (median)\n",
        "- **Q90** = Flow exceeded 90% of time (low flow)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stats_section",
      "metadata": {
        "id": "stats_section"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 9: Practical Statistics for H&H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stats_cell",
      "metadata": {
        "id": "stats_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# BASIC SUMMARY STATISTICS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=== Discharge Summary Statistics ===\")\n",
        "print(f\"\\nPeriod: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
        "print(f\"Total days: {len(df):,}\")\n",
        "\n",
        "print(f\"\\n--- Central Tendency ---\")\n",
        "print(f\"  Mean:   {df['Q_cfs'].mean():>10,.0f} cfs\")\n",
        "print(f\"  Median: {df['Q_cfs'].median():>10,.0f} cfs\")\n",
        "\n",
        "print(f\"\\n--- Extremes ---\")\n",
        "print(f\"  Minimum: {df['Q_cfs'].min():>10,.0f} cfs on {df['Q_cfs'].idxmin().strftime('%Y-%m-%d')}\")\n",
        "print(f\"  Maximum: {df['Q_cfs'].max():>10,.0f} cfs on {df['Q_cfs'].idxmax().strftime('%Y-%m-%d')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "percentile_cell",
      "metadata": {
        "id": "percentile_cell"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PERCENTILE STATISTICS\n",
        "# =============================================================================\n",
        "\n",
        "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
        "\n",
        "print(\"=== Flow Percentiles ===\")\n",
        "print(\"\\nPercentile  |  Flow (cfs)\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for p in percentiles:\n",
        "    value = df['Q_cfs'].quantile(p/100)\n",
        "    print(f\"    P{p:<3}    |  {value:>10,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exercises_intro",
      "metadata": {
        "id": "exercises_intro"
      },
      "source": [
        "---\n",
        "\n",
        "## Practice Exercises ðŸŽ¯\n",
        "\n",
        "Try these exercises to reinforce what you've learned. Attempt them without looking at solutions first, then use your AI assistant if stuck.\n",
        "\n",
        "### Exercise 1: Parse and Index\n",
        "1. Load the CSV again into `df2`\n",
        "2. Rename `time` â†’ `date`, `value` â†’ `Q_cfs`\n",
        "3. Convert `date` to datetime and set as index\n",
        "4. Print the date range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ex1",
      "metadata": {
        "id": "ex1"
      },
      "outputs": [],
      "source": [
        "# EXERCISE 1 - YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ex2_section",
      "metadata": {
        "id": "ex2_section"
      },
      "source": [
        "### Exercise 2: Monthly Plot (Mean and Max)\n",
        "1. Compute monthly mean AND monthly max discharge\n",
        "2. Plot both on the same figure with a legend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ex2",
      "metadata": {
        "id": "ex2"
      },
      "outputs": [],
      "source": [
        "# EXERCISE 2 - YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ex3_section",
      "metadata": {
        "id": "ex3_section"
      },
      "source": [
        "### Exercise 3: Convert to cms and Report Percentile\n",
        "1. Create a `Q_cms` column\n",
        "2. Compute the 90th percentile (P90) of `Q_cms`\n",
        "3. Print it with a clear label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ex3",
      "metadata": {
        "id": "ex3"
      },
      "outputs": [],
      "source": [
        "# EXERCISE 3 - YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ex4_section",
      "metadata": {
        "id": "ex4_section"
      },
      "source": [
        "### Exercise 4: 14-Day Rolling Statistics\n",
        "1. Create a 14-day rolling mean from `Q_cfs`\n",
        "2. Find the date where the rolling mean is maximum\n",
        "3. Make a plot showing daily flow and 14-day rolling mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ex4",
      "metadata": {
        "id": "ex4"
      },
      "outputs": [],
      "source": [
        "# EXERCISE 4 - YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ex5_section",
      "metadata": {
        "id": "ex5_section"
      },
      "source": [
        "### Exercise 5: FDC Function (Challenge)\n",
        "Write a function `flow_duration_curve(series)` that:\n",
        "- Takes a pandas Series of flows\n",
        "- Returns a DataFrame with `exceedance_pct` and `flow`\n",
        "- Creates an FDC plot\n",
        "\n",
        "### ðŸ¤– AI Prompt for Exercise 5:\n",
        "```\n",
        "Help me write a Python function called 'flow_duration_curve' that:\n",
        "1. Takes a pandas Series of discharge values\n",
        "2. Calculates exceedance probability for each sorted value\n",
        "3. Returns a DataFrame with 'exceedance_pct' and 'flow'\n",
        "4. Creates a flow duration curve plot\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ex5",
      "metadata": {
        "id": "ex5"
      },
      "outputs": [],
      "source": [
        "# EXERCISE 5 - YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ‰ What You Can Now Do\n",
        "\n",
        "Congratulations! You've learned the core building blocks for time series analysis in H&H:\n",
        "\n",
        "| Skill | What You Learned |\n",
        "|-------|------------------|\n",
        "| **Data Loading** | Read CSV files, inspect data, clean columns |\n",
        "| **Datetime Handling** | Parse dates, set indexes, time-based slicing |\n",
        "| **Resampling** | Convert daily â†’ monthly/annual, rolling averages |\n",
        "| **Visualization** | Hydrographs, box plots, flow duration curves |\n",
        "| **Statistics** | Percentiles, annual summaries, basic metrics |\n",
        "| **AI Collaboration** | Use AI to explain, debug, and extend your code |\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "Future lessons can build on these skills:\n",
        "- **Frequency analysis** (annual maxima, fitting distributions)\n",
        "- **Event detection** (identifying peaks, hydrograph separation)\n",
        "- **Rainfall-runoff analysis** (comparing precipitation and discharge)\n",
        "\n",
        "### ðŸ¤– Final AI Prompt: Adapting to Your Data\n",
        "\n",
        "```\n",
        "I completed a time series analysis lesson using USGS discharge data.\n",
        "Now I want to apply the same workflow to [describe your data].\n",
        "\n",
        "My data is in [format] and has columns for [list columns].\n",
        "\n",
        "What changes do I need to make to adapt the code?\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
